{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca43772",
   "metadata": {},
   "source": [
    "# Análisis de Escritos según Ámbito 1: Aspectos de Estructura Global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209005d2",
   "metadata": {},
   "source": [
    "El prompt, formulado usando CHATGPT, permite evaluar un texto de manera automática según los tres criterios de la rúbrica académica:  \n",
    "\n",
    "1. **Estructura global: Introducción**  \n",
    "   Evalúa si el texto presenta una introducción clara, bien contextualizada o simplemente mencionada.  \n",
    "\n",
    "2. **Estructura global: Conclusión o cierre**  \n",
    "   Revisa si el texto cierra correctamente con una conclusión, una proyección de la tesis o solo un comentario.  \n",
    "\n",
    "3. **Progresión textual**  \n",
    "   Analiza el uso de párrafos y si cada uno aporta una idea principal distinta.  \n",
    "\n",
    "El resultado de la evaluación se entrega en **formato JSON** para facilitar su interpretación y posterior uso en sistemas automáticos o reportes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6869f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\06\\a1_estructura.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_estructura = \"\"\"\n",
    "Evalúa el siguiente texto usando esta rúbrica:\n",
    "\n",
    "1. Estructura global: Introducción\n",
    "- Nivel 4: Se identifica claramente una introducción en la que se presenta y contextualiza el tema del texto (qué, quiénes, dónde, cuándo, etc.).\n",
    "- Nivel 3: Se identifica claramente una introducción en la que se menciona el tema del texto, pero sin suficiente contextualización.\n",
    "- Nivel 2: La estructura del texto no es clara, pero es posible inferir la presencia de una introducción amalgamada en otras oraciones o párrafos.\n",
    "- Nivel 1: No es posible identificar una introducción en el texto.\n",
    "\n",
    "2. Estructura global: Conclusión o cierre\n",
    "- Nivel 4: En la estructura del texto se distingue un cierre en el que se concluye o se proyecta la tesis.\n",
    "- Nivel 3: En la estructura del texto se distingue un cierre a modo de comentario.\n",
    "- Nivel 2: La estructura del texto no es clara, pero es posible inferir la presencia de una conclusión o cierre amalgamada en otras oraciones o párrafos.\n",
    "- Nivel 1: No se identifica una conclusión o cierre en el texto.\n",
    "\n",
    "3. Progresión textual (uso de párrafos e inclusión de información principal)\n",
    "- Nivel 4: El texto presenta párrafos claramente identificables y en cada uno se reconoce una información principal distinta a la del párrafo anterior.\n",
    "- Nivel 3: El texto presenta párrafos claramente identificables, pero en un párrafo se repite información de algún párrafo anterior.\n",
    "- Nivel 2: El texto presenta párrafos claramente identificables, pero en dos párrafos se repite información de algún párrafo anterior.\n",
    "- Nivel 1: No se presentan párrafos claramente identificables o en todos los párrafos se repite información anterior.\n",
    "\n",
    "Devuelve la evaluación **únicamente en formato JSON** con la siguiente estructura:\n",
    "\n",
    "{{\n",
    "  \"introduccion\": {{\n",
    "    \"nivel\": (número de 1 a 4),\n",
    "    \"justificacion\": \"explicación breve\"\n",
    "  }},\n",
    "  \"conclusion_cierre\": {{\n",
    "    \"nivel\": (número de 1 a 4),\n",
    "    \"justificacion\": \"explicación breve\"\n",
    "  }},\n",
    "  \"progresion_textual\": {{\n",
    "    \"nivel\": (número de 1 a 4),\n",
    "    \"justificacion\": \"explicación breve\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):    \n",
    "    prompt_estructura_a1 = prompt_estructura.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_estructura_a1}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"06\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"a1_estructura.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4d4347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\06\\a1_introduccion.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_introduccion = \"\"\"\n",
    "Evalúa el siguiente texto usando esta rúbrica:\n",
    "\n",
    "**Estructura global: Introducción**\n",
    "- Nivel 4: Se identifica claramente una introducción en la que se presenta y contextualiza el tema del texto (qué, quiénes, dónde, cuándo, etc.).\n",
    "- Nivel 3: Se identifica claramente una introducción en la que se menciona el tema del texto, pero sin suficiente contextualización.\n",
    "- Nivel 2: La estructura del texto no es clara, pero es posible inferir la presencia de una introducción amalgamada en otras oraciones o párrafos.\n",
    "- Nivel 1: No es posible identificar una introducción en el texto.\n",
    "\n",
    "Devuelve la evaluación **únicamente en formato JSON** con la siguiente estructura:\n",
    "\n",
    "{{\n",
    "  \"introduccion\": {{\n",
    "    \"nivel\": (número de 1 a 4),\n",
    "    \"justificacion\": \"explicación breve\"\n",
    "}}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):    \n",
    "    prompt_introduccion_a1 = prompt_introduccion.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_introduccion_a1}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"06\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"a1_introduccion.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6d8d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\06\\a1_conclusion_cierre.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_conclusion_cierre = \"\"\"\n",
    "Evalúa el siguiente texto usando esta rúbrica:\n",
    "\n",
    "**Estructura global: Conclusión o cierre**\n",
    "- Nivel 4: En la estructura del texto se distingue un cierre en el que se concluye o se proyecta la tesis.\n",
    "- Nivel 3: En la estructura del texto se distingue un cierre a modo de comentario.\n",
    "- Nivel 2: La estructura del texto no es clara, pero es posible inferir la presencia de una conclusión o cierre amalgamada en otras oraciones o párrafos.\n",
    "- Nivel 1: No se identifica una conclusión o cierre en el texto.\n",
    "Devuelve la evaluación **únicamente en formato JSON** con la siguiente estructura:\n",
    "\n",
    "{{\n",
    "  \"conclusion_cierre\": {{\n",
    "    \"nivel\": (número de 1 a 4),\n",
    "    \"justificacion\": \"explicación breve\"\n",
    "}}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):    \n",
    "    prompt_conclusion_cierre_a1 = prompt_conclusion_cierre.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_conclusion_cierre_a1}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"06\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"a1_conclusion_cierre.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff20fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\06\\a1_progresion_textual.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_progresion_textual = \"\"\"\n",
    "Evalúa el siguiente texto usando esta rúbrica:\n",
    "\n",
    "**Progresión textual (uso de párrafos e inclusión de información principal)**\n",
    "- Nivel 4: El texto presenta párrafos claramente identificables y en cada uno se reconoce una información principal distinta a la del párrafo anterior.\n",
    "- Nivel 3: El texto presenta párrafos claramente identificables, pero en un párrafo se repite información de algún párrafo anterior.\n",
    "- Nivel 2: El texto presenta párrafos claramente identificables, pero en dos párrafos se repite información de algún párrafo anterior.\n",
    "- Nivel 1: No se presentan párrafos claramente identificables o en todos los párrafos se repite información anterior.\n",
    "\n",
    "{{\n",
    "  \"progresion_textual\": {{\n",
    "    \"nivel\": (número de 1 a 4),\n",
    "    \"justificacion\": \"explicación breve\"\n",
    "}}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):    \n",
    "    prompt_progresion_textual_a1 = prompt_progresion_textual.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_progresion_textual_a1}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"06\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"a1_progresion_textual.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
