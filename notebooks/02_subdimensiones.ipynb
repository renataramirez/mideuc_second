{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d5ac2e",
   "metadata": {},
   "source": [
    "# Análisis automático orientado a corrección de textos\n",
    "\n",
    "En este cuaderno estoy probando diferentes **dimensiones de corrección y análisis de textos** mediante el uso de modelos de lenguaje (Azure OpenAI).  \n",
    "\n",
    "El objetivo es evaluar y detectar errores en tres grandes dimensiones:\n",
    "\n",
    "1. **Ortografía**  \n",
    "   - Acentual: reglas ortográficas que rigen la acentuación de la lengua española.\n",
    "   - Literal: omisiones, sustituciones, adiciones de letras, mayúsculas.  \n",
    "   - Puntual: uso incorrecto de comas, puntos, signos de interrogación y exclamación, etc. \n",
    "\n",
    "2. **Vocabulario**  \n",
    "   - Amplitud: detección de repeticiones innecesarias dentro de un mismo párrafo, considerando sustantivos, adjetivos, verbos y adverbios.  \n",
    "   - Precisión léxica: reconocimiento del uso incorrecto del significado de palabras, de los extranjerismos incorrectamento formulados y de palabras e ideas reiteradadas excesivamente.\n",
    "   - Adecuación al registro de habla formal: identificación del empleo de modo de comunicación escrita que se ajusta a la norma culta de la lengua, caracterizado por un uso cuidadoso y preciso del vocabulario y la gramática.\n",
    "\n",
    "3. **Cohesión textual**  \n",
    "   - Concordancia gramatical: sujeto-predicado, sustantivo-adjetivo, tiempos verbales en enumeraciones y cláusulas condicionales.  \n",
    "   - Conexión textual: uso de preposiciones, locuciones, conectores adecuados y organizadores textuales.  \n",
    "   - Referencias y correferencias: detección de pronombres o expresiones sin referente claro, como *esto*, *lo anterior*, etc.  \n",
    "\n",
    "Cada dimensión se prueba sobre los textos del dataset **`escritos_seleccionados_a1.xlsx`**, y los resultados se almacenan en archivos JSON, manteniendo un registro estructurado de los errores detectados.  \n",
    "\n",
    "El flujo de trabajo consiste en evaluar cada subdimensión mediante llamadas a la API de Azure OpenAI, siguiendo los criterios definidos en la rúbrica elaborada por expertos (versión del 15 de septiembre de 2025), la cual establece tanto los aspectos de evaluación como los puntajes asociados. Para cada una de las subdimensiones se realiza una llamada independiente por cada uno de los 10 textos contenidos en el documento escritos_seleccionados_ort.xlsx.\n",
    "\n",
    "*Documento elaborado por Renata Ramírez, practicante MIDEUC.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076caaa7",
   "metadata": {},
   "source": [
    "## 1. Ortografía"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684c288",
   "metadata": {},
   "source": [
    "### Acentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e3e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\ort_acentual.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_acentual_template = \"\"\"\n",
    "Identifica EXCLUSIVAMENTE los errores relacionados con el uso de tildes en español en un texto que te entregaré, retornando un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Considera las reglas generales (palabras agudas, graves, esdrújulas y sobreesdrújulas) y las reglas especiales (acento diacrítico y acento dierético) que rigen el uso de tildes en español.\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:\n",
    "\n",
    "{{\n",
    "  \"errores_acentuales\": {{\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        \"error_3\": [\"error → corrección\"],\n",
    "        ...\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- SOLO reporta errores en los que la diferencia entre error y corrección sea la presencia o ausencia de una tilde.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):    \n",
    "    prompt_acentual = prompt_acentual_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_acentual}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_acentual.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a944b42",
   "metadata": {},
   "source": [
    "### Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450dc186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\ort_literal.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_literal_template = \"\"\"\n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Corrige ÚNICAMENTE los siguientes tipos de errores:\n",
    "\n",
    "1. Mayúsculas ausentes: inicio de párrafo, tras punto, nombres propios. Ej: \". ahora\" → \". Ahora\", \"madrid\" → \"Madrid\".\n",
    "2. Omisión de letras: ej. \"alchol\" → \"alcohol\", \"gerra\" → \"guerra\", \"aora\" → \"ahora\".\n",
    "3. Sustitución de letras: ej. \"girafa\" → \"jirafa\", \"obeja\" → \"oveja\".\n",
    "4. Adición de letras: ej. \"rrallado\" → \"rallado\", \"exhuberante\" → \"exuberante\". Incluye \"en carro\": ej. \"apartir\" → \"a partir\", \"através\" → \"a través\".\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:\n",
    "\n",
    "{{\n",
    "  \"errores_ortografia_literal\": {{\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        ...\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Texto a evaluar\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO revises ni corrijas tildes.\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_literal = prompt_literal_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_literal}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_literal.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4e6a4",
   "metadata": {},
   "source": [
    "### Puntual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81e2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\ort_puntual.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_puntual_template = \"\"\"\n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Tu tarea es corregir ÚNICAMENTE errores relacionados con signos de puntuación, de acuerdo con las normas de la RAE:\n",
    "\n",
    "- Incorrecta presencia de una coma u omisión de una coma requerida.\n",
    "- Incorrecta presencia de un punto u omisión de un punto requerido (final, seguido o aparte).\n",
    "- Incorrecta presencia de un punto y coma. NO sanciones cuando la ausencia de punto y coma.\n",
    "- Incorrecta presencia u omisión de signos de exclamación e interrogación.\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:\n",
    "\n",
    "{{\n",
    "  \"errores_ortografia_puntual\": {{\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        ...\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Instrucciones de la estructura:\n",
    "- Ante un error de puntuación, el 'error' y 'corrección' en el JSON deben contener la palabra que antecede al signo faltante y la que lo sigue. Por ejemplo, si el texto decía \"Para lograr un desarrollo sostenible es necesario cambiar nuestro hábitos de consumo\", \"error_i\" debe ser [\"sostenible es → sostenible, es\"]\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### Instrucciones CRÍTICAS:\n",
    "- NO revises ni corrijas tildes\n",
    "- Cada error y corrección debe mostrarse con el fragmento MÁS BREVE posible que contenga el error (no más de 20 caracteres).\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_puntual = prompt_puntual_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_puntual}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_puntual.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed411e3",
   "metadata": {},
   "source": [
    "## 2. Vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212d332",
   "metadata": {},
   "source": [
    "### Amplitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c239eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\voc_amplitud.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_amplitud_template = \"\"\"\n",
    "Cuenta las palabras repetidas siguiendo las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Deberas contar las palabras repetidas en el texto, siguiendo las siguientes reglas y excepciones.\n",
    "\n",
    "- Solo contabilizar repeticiones en SUSTANTIVOS, ADJETIVOS, VERBOS y ADVERBIOS. No incluyas conectores.\n",
    "- NO cuentes palabras repetidas usadas como figura retórica de énfasis, lo que se advierte rápidamente por el sentido del texto.  \n",
    "- No contar conjugaciones verbales ni perífrasis verbales (auxiliar + infinitivo/gerundio/participio).\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:\n",
    "\n",
    "{{\n",
    "  \"errores_vocabulario_amplitud\": {{\n",
    "        \"palabra1\": [\"n veces\"],\n",
    "        \"palabra2\": [\"n veces\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Texto a evaluar\n",
    "{essay}\n",
    "\n",
    "### Instrucciones CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    parrafos = [p.strip() for p in texto.split(\"\\n\") if p.strip()]  \n",
    "\n",
    "    errores_por_texto = {\"id_texto\": i, \"errores_vocabulario_amplitud\": {}}\n",
    "\n",
    "    for j, parrafo in enumerate(parrafos, start=1):\n",
    "        prompt_amplitud = prompt_amplitud_template.format(essay=parrafo)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "            {\"role\": \"user\", \"content\": prompt_amplitud}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=DEPLOYMENT_GPT,\n",
    "                messages=messages,\n",
    "                # temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "\n",
    "            respuesta_limpia = response.choices[0].message.content.strip()\n",
    "            resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "            errores_por_texto[\"errores_vocabulario_amplitud\"][f\"parrafo_{j}\"] = resultado_json.get(\"errores_vocabulario_amplitud\", {})\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error al parsear JSON en texto {i}, párrafo {j}: {e}\")\n",
    "            print(\"Respuesta cruda recibida:\")\n",
    "            print(respuesta_limpia)\n",
    "\n",
    "    resultados.append(errores_por_texto)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_amplitud.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163e45f",
   "metadata": {},
   "source": [
    "### Precisión léxica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd8d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\voc_precision.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_precision_template = \"\"\"\n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Identifica como error si se cumple alguno de los siguientes criterios:\n",
    "\n",
    "A) USO INCORRECTO DE SIGNIFICADOS:\n",
    "- Detecta palabras usadas con un significado equivocado que cambien el sentido del texto. La palabra usada debe existir y estar correctamente escrita.\n",
    "- Ejemplo: “absceso” por “acceso”, “actitud” por “aptitud”.\n",
    "\n",
    "B) EXTRANJERISMOS:\n",
    "- Señala extranjerismos que NO estén en comillas, cursiva o introducidos explícitamente por el autor.\n",
    "- Ejemplo incorrecto: usar \"online\" sin comillas ni contexto en vez de “en línea”.\n",
    "- No sanciones extranjerismos correctos o presentados como citas.\n",
    "\n",
    "C) REDUNDANCIAS:\n",
    "- Detecta repeticiones innecesarias de palabras o ideas.\n",
    "- Ejemplo: “salir para afuera”, “volar por los aires”, “hace un tiempo atrás”.\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:\n",
    "\n",
    "{{\n",
    "  \"errores_precision\": {{\n",
    "        \"error_1\": [\"error → corrección\", CRITERIO],\n",
    "        \"error_2\": [\"error → corrección\", CRITERIO],\n",
    "        ...,\n",
    "        \"error_n\": [\"error → corrección\", CRITERIO]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Reglas para la estructura\n",
    "- Muestra el fragmento MÁS BREVE posible con el error\n",
    "- En CRITERIO indica \"USO INCORRECTO DE SIGNIFICADOS\", \"EXTRANJERISMO\" o \"REDUNDANCIA\".\n",
    "\n",
    "### Texto a evaluar\n",
    "{essay}\n",
    "\n",
    "REGLAS:\n",
    "- Enumera todos los errores encontrados bajo la clave \"errores_vocabulario_precision\".\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_precision = prompt_precision_template.format(essay=texto)\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_precision}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_precision.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e747ad",
   "metadata": {},
   "source": [
    "### Registro formal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89a72a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\voc_formal.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_formal_template = \"\"\"\n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Sanciona como error únicamente los siguientes casos:\n",
    "\n",
    "1) SEGUNDA PERSONA SINGULAR:\n",
    "Sanciona el uso del pronombre “tú” y/o formas verbales conjugadas en segunda persona singular PARA EXPONER GENERALIZACIONES o PROCEDIMIENTOS QUE DEBERÍAN EXPRESARSE EN FORMA IMPERSONAL o GENERAL.\n",
    "- Por ejemplo: \"Cuando postulas a un trabajo, tú tienes que pasar una entrevista\".\n",
    "\n",
    "2) ABREVIACIONES:\n",
    "Sanciona palabras abreviadas propias de la oralidad.\n",
    "- Por ejemplo: “profe” por “profesor/a”, “finde” por “fin de semana”.\n",
    "\n",
    "3) COLOQUIALISMOS:\n",
    "Sanciona el uso de expresiones coloquiales (expresiones propias de la conversación informal)\n",
    "- Por ejemplo: “socio” por “amigo”, “cachar” por “comprender” o “darse cuenta”, “pega” por “trabajo”; el uso de calificativos más expresivos: “mina” por “guapa”, “bacán” por “excelente”, “pichiruche” por “insignificante”; el uso de diminutivos y el prefijo “super” para amplificar valor.\n",
    "\n",
    "4) CÓDIGO ESCRITO NO FORMAL:\n",
    "Sanciona la sustitución de letras por símbolos para representar palabras\n",
    "- Por ejemplo: \"q’\" por \"que\", \"total%\" por \"totalmente\", \"publicaØ\" por \"publicación\").\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura::\n",
    "\n",
    "{{\n",
    "  \"errores_vocabulario_formal\": {{\n",
    "        \"error_1\": [\"error → corrección sugerida\", CRITERIO],\n",
    "        \"error_2\": [\"error → corrección sugerida\", CRITERIO],\n",
    "        ...,\n",
    "        \"error_n\": [\"error → corrección sugerida\", CRITERIO]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Reglas sobre el formato:\n",
    "- En \"CRITERIO\", indica si el criterio es \"SEGUNDA PERSONA SINGULAR\", \"ABREVIACIONES\", \"COLOQUIALISMOS\" o \"CÓDIGO ESCRITO NO FORMAL\".\n",
    "- En cada caso, muestra el fragmento MÁS BREVE posible con el error.\n",
    "- Entrega una corrección sugerida acorde al registro formal.\n",
    "\n",
    "### Texto a analizar:\n",
    "{essay}\n",
    "\n",
    "### Importante:\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_formal = prompt_formal_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_formal}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            #temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_formal.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")\n",
    "\n",
    "# 4) CÓDIGO ESCRITO NO FORMAL:\n",
    "# - Detecta usos innecesarios de caracteres o símbolos en el español, sin incluiir til\n",
    "# que alteren la escritura formal con símbolos o caracteres que no son letras ni tildes.\n",
    "# - Ejemplos: \"q’\" por \"que\", \"total%\" por \"totalmente\", \"publicaØ\" por \"publicación\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a14b0",
   "metadata": {},
   "source": [
    "## 3. Cohesión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e02a6",
   "metadata": {},
   "source": [
    "### Concordancia gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9be19cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\coh_concordancia.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_concordancia_template = \"\"\"\n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Consideraremos faltas de concordancia gramatical SOLO los siguientes casos:\n",
    "\n",
    "1) Falta de concordancia (en género o número) entre **sustantivo y adjetivo**.\n",
    "\n",
    "2) Falta de concordancia (en género o número) entre **sujeto y predicado**.\n",
    "\n",
    "3) Falta de concordancia (en género o número) entre **pronombres relativos y sus antecedentes**.\n",
    "\n",
    "Faltas de consistencia verbal SOLO en los siguientes casos:\n",
    "\n",
    "A) Cambio de tiempo verbal en una enumeración de acciones. Por ejemplo \"Se MIDE el nivel de agua, se OBSERVAN los cambios en la sustancia y se REGISTRARÁ el proceso por escrito\".\n",
    "\n",
    "B) Uso de tiempos no adecuados en cláusulas condicionales y concesivas. Por ejemplo: \"Si me HUBIERAN invitado, HABRÍA venido\" o \"Aunque los químicos se HUBIERAN resguardado de la temperatura, igualmente HABRÍAN perdido su calidad\".\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:  \n",
    "\n",
    "{{\n",
    "  \"errores_cohesion_concordancia\": {{\n",
    "    \"error_1\": [\"error → corrección\", \"tipo: sustantivo-adjetivo\"],\n",
    "    \"error_2\": [\"error → corrección\", \"tipo: sujeto-predicado\"],\n",
    "    \"error_3\": [\"error → corrección\", \"tipo: pronombre-relativo\"],\n",
    "    \"error_4\": [\"error → corrección\", \"tipo: A\"],\n",
    "    \"error_5\": [\"error → corrección\", \"tipo: B\"],\n",
    "    ...\n",
    "    \"error_n\": [\"error → corrección\", \"tipo: ...\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Reglas sobre la estructura:\n",
    "- En tipo de error indica \"sustantivo-adjetivo\", \"sujeto-predicado\", \"pronombre-relativo\", \"A\" (enumeración de acciones) o \"B\" (cláusulas).\n",
    "- En cada caso, muestra el fragmento MÁS BREVE posible con el error.\n",
    "- Entrega la corrección del error.\n",
    "\n",
    "### Texto a analizar:\n",
    "{essay}\n",
    "\n",
    "### Instrucciones críticas:  \n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.  \n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_concordancia = prompt_concordancia_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_concordancia}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            #temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_concordancia.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671de2a2",
   "metadata": {},
   "source": [
    "### Conexión textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b437ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\coh_conexion.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_conexion_template = \"\"\"\n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.\n",
    "\n",
    "Se consideran errores únicamente los siguientes casos:\n",
    "\n",
    "1. Uso inadecuado de preposiciones o rección: falta la preposición o uso de una preposición incorrecta.  \n",
    "   - Incluye queísmo (uso de \"que\" sin \"de\" cuando corresponde) y dequeísmo (uso de \"de que\" cuando solo corresponde \"que\").  \n",
    "2. Uso inadecuado de locuciones preposicionales u otras construcciones lexicales de carácter conectivo (ej.: \"sobre la base de\", \"a razón de\", \"en relación con\") **cuando afecten la lógica de conexión oracional y/o textual**.  \n",
    "3. Ausencia de conectores o uso de conectores inadecuados para expresar la idea que se busca; mal uso de organizadores textuales (ej.: \"en primer lugar\", \"por un lado\", etc.).\n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura: \n",
    "\n",
    "{{\n",
    "  \"errores_cohesion_conexion\": {{\n",
    "    \"error_1\": [\"error → corrección\", \"tipo: preposición/rección\"],\n",
    "    \"error_2\": [\"error → corrección\", \"tipo: queísmo\"],\n",
    "    \"error_3\": [\"error → corrección\", \"tipo: dequeísmo\"],\n",
    "    \"error_4\": [\"error → corrección\", \"tipo: locución-preposicional\"],\n",
    "    \"error_5\": [\"error → corrección\", \"tipo: conector-ausente\"],\n",
    "    \"error_6\": [\"error → corrección\", \"tipo: conector-inadecuado\"],\n",
    "    ...\n",
    "    \"error_n\": [\"error → corrección\", \"tipo: ...\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Reglas sobre la estructura:\n",
    "- En tipo de error indica \"preposición/rección\", \"queísmo\", \"dequeísmo\", \"locución-preposicional\", \"conector-ausente\" o \"conector-inadecuado\".\n",
    "- En cada caso, muestra el fragmento MÁS BREVE posible con el error.\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### Importante:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_conexion = prompt_conexion_template.format(essay=texto)\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_conexion}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_conexion.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed729a1d",
   "metadata": {},
   "source": [
    "### Referencias y correferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a29d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\coh_referencias.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_referencias_template = \"\"\"  \n",
    "Identifica los errores EXCLUSIVAMENTE según las instrucciones que se detallarán, para un texto que te entregaré. Debes retornar un diccionario JSON válido según la estructura que se detallará más adelante.  \n",
    "\n",
    "Considera errores únicamente según el siguiente criterio:\n",
    "\n",
    "- Pronombres o mecanismos de correferencia que no tengan un referente claro en el texto. Por ejemplo: \"esto\", \"lo anterior\", \"esa situación\".  \n",
    "\n",
    "Tu respuesta debe ser un JSON válido que siga exactamente esta estructura:\n",
    "\n",
    "{{\n",
    "  \"errores_cohesion_referencia\": {{\n",
    "    \"error_1\": [\"error → corrección\", \"tipo: pronombre-sin-referencia\"],\n",
    "    \"error_2\": [\"error → corrección\", \"tipo: pronombre-sin-referencia\"],\n",
    "    ...\n",
    "    \"error_n\": [\"error → corrección\", \"tipo: pronombre-sin-referencia\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "### Reglas de la estructura:\n",
    "- Cada error debe mostrarse con el fragmento MÁS BREVE posible que contenga el error (no frases completas).\n",
    "- En 'tipo' entrega pronombre-sin-referencia para todos los errores\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### Instrucciones criticas \n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON. \n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_referencias = prompt_referencias_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_referencias}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_referencias.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
