{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d5ac2e",
   "metadata": {},
   "source": [
    "# Análisis automático orientado a corrección de textos\n",
    "\n",
    "En este cuaderno estoy probando diferentes **dimensiones de corrección y análisis de textos** mediante el uso de modelos de lenguaje (Azure OpenAI).  \n",
    "\n",
    "El objetivo es evaluar y detectar errores en tres grandes dimensiones:\n",
    "\n",
    "1. **Ortografía**  \n",
    "   - Acentual: reglas ortográficas que rigen la acentuación de la lengua española.\n",
    "   - Literal: omisiones, sustituciones, adiciones de letras, mayúsculas.  \n",
    "   - Puntual: uso incorrecto de comas, puntos, signos de interrogación y exclamación, etc. \n",
    "\n",
    "2. **Vocabulario**  \n",
    "   - Amplitud: detección de repeticiones innecesarias dentro de un mismo párrafo, considerando sustantivos, adjetivos, verbos y adverbios.  \n",
    "   - Precisión léxica: reconocimiento del uso incorrecto del significado de palabras, de los extranjerismos incorrectamento formulados y de palabras e ideas reiteradadas excesivamente.\n",
    "   - Adecuación al registro de habla formal: identificación del empleo de modo de comunicación escrita que se ajusta a la norma culta de la lengua, caracterizado por un uso cuidadoso y preciso del vocabulario y la gramática.\n",
    "\n",
    "3. **Cohesión textual**  \n",
    "   - Concordancia gramatical: sujeto-predicado, sustantivo-adjetivo, tiempos verbales en enumeraciones y cláusulas condicionales.  \n",
    "   - Conexión textual: uso de preposiciones, locuciones, conectores adecuados y organizadores textuales.  \n",
    "   - Referencias y correferencias: detección de pronombres o expresiones sin referente claro, como *esto*, *lo anterior*, etc.  \n",
    "\n",
    "Cada dimensión se prueba sobre los textos del dataset **`escritos_seleccionados_a1.xlsx`**, y los resultados se almacenan en archivos JSON, manteniendo un registro estructurado de los errores detectados.  \n",
    "\n",
    "El flujo de trabajo consiste en evaluar cada subdimensión mediante llamadas a la API de Azure OpenAI, siguiendo los criterios definidos en la rúbrica elaborada por expertos (versión del 15 de septiembre de 2025), la cual establece tanto los aspectos de evaluación como los puntajes asociados. Para cada una de las subdimensiones se realiza una llamada independiente por cada uno de los 10 textos contenidos en el documento escritos_seleccionados_ort.xlsx.\n",
    "\n",
    "*Documento elaborado por Renata Ramírez, practicante MIDEUC.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076caaa7",
   "metadata": {},
   "source": [
    "## 1. Ortografía"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684c288",
   "metadata": {},
   "source": [
    "### Acentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e3e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\ort_acentual.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_acentual = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.\n",
    "\n",
    "EVALÚA Y CORRIGE EXCLUSIVAMENTE los errores en el texto relacionados con el uso de tildes en español. \n",
    "Considera las reglas generales (palabras agudas, graves, esdrújulas y sobreesdrújulas) \n",
    "y las reglas especiales (acento diacrítico y acento dierético).\n",
    "\n",
    "Tu respuesta debe seguir exactamente esta estructura:\n",
    "\n",
    "{\n",
    "  \"errores_acentuales\": {\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        \"error_3\": [\"error → corrección\"],\n",
    "        ...\n",
    "  }\n",
    "}\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- SOLO reporta errores en los que la diferencia entre error y corrección sea la presencia o ausencia de una tilde.\n",
    "- NO señales problemas de ortografía, puntuación, vocabulario ni otros aspectos.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_acentual},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_acentual.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a944b42",
   "metadata": {},
   "source": [
    "### Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "450dc186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\ort_literal.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_literal = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. \n",
    "\n",
    "Corrige ÚNICAMENTE los siguientes tipos de errores:\n",
    "\n",
    "1. Mayúsculas ausentes: inicio de párrafo, tras punto, nombres propios. Ej: \". ahora\" → \". Ahora\", \"madrid\" → \"Madrid\".\n",
    "2. Omisión de letras: ej. \"alchol\" → \"alcohol\", \"gerra\" → \"guerra\", \"aora\" → \"ahora\".\n",
    "3. Sustitución de letras: ej. \"girafa\" → \"jirafa\", \"obeja\" → \"oveja\".\n",
    "4. Adición de letras: ej. \"rrallado\" → \"rallado\", \"exhuberante\" → \"exuberante\". Incluye \"en carro\": ej. “apartir” → “a partir”, “através” → “a través”.\n",
    "\n",
    "INSTRUCCIÓN CRÍTICA:\n",
    "- NO revises ni corrijas tildes (acentos ortográficos). \n",
    "- Cualquier palabra cuya única diferencia con la forma correcta sea la presencia o ausencia de una tilde DEBE SER IGNORADA.\n",
    "- Si la única “corrección” que encuentras sería añadir o quitar una tilde, NO la reportes.\n",
    "\n",
    "Formato de respuesta OBLIGATORIO (solo JSON válido):\n",
    "\n",
    "{\n",
    "  \"errores_ortografia_literal\": {\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        ...\n",
    "  }\n",
    "}\n",
    "\n",
    "Reglas:\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json.\n",
    "- El JSON debe empezar con { y terminar con }.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_literal},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_literal.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4e6a4",
   "metadata": {},
   "source": [
    "### Puntual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e81e2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\ort_puntual.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_puntual = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. \n",
    "\n",
    "Tu tarea es corregir ÚNICAMENTE errores relacionados con signos de puntuación, de acuerdo con las normas de la RAE:\n",
    "\n",
    "- Uso de la coma.\n",
    "- Uso del punto (seguido, aparte y final).\n",
    "- Uso del punto y coma.\n",
    "- Uso de signos de exclamación e interrogación.\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- NO revises ni corrijas tildes (acentos ortográficos). \n",
    "- NO corrijas errores de ortografía literal (letras omitidas, añadidas, sustituidas, mayúsculas, etc.).\n",
    "- NO evalúes vocabulario ni estilo.\n",
    "- Si un posible “error” solo se diferencia de la forma correcta por la presencia o ausencia de una tilde, DEBES IGNORARLO.\n",
    "\n",
    "Formato de salida (solo JSON válido):\n",
    "\n",
    "{\n",
    "  \"errores_ortografia_puntual\": {\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        ...\n",
    "  }\n",
    "}\n",
    "\n",
    "Reglas:\n",
    "- Cada error y corrección debe mostrarse con el fragmento MÁS BREVE posible que contenga el error (no más de 20 caracteres).\n",
    "- NO incluyas el texto completo corregido.\n",
    "- Devuelve SOLO JSON válido, sin markdown ni ```json.\n",
    "- El JSON debe comenzar con { y terminar con }.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_puntual},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_puntual.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed411e3",
   "metadata": {},
   "source": [
    "## 2. Vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212d332",
   "metadata": {},
   "source": [
    "### Amplitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c239eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\voc_amplitud.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_amplitud = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.\n",
    "\n",
    "Analiza EXCLUSIVAMENTE la dimensión de AMPLITUD DE VOCABULARIO en un único PÁRRAFO recibido, según las siguientes reglas:\n",
    "\n",
    "- El emisor debe usar sinónimos y correferencias para evitar repeticiones innecesarias.\n",
    "- Se sanciona la repetición de una misma palabra dentro de un mismo párrafo.\n",
    "- EXCEPCIÓN: No sancionar repeticiones cuando se trate de una figura retórica de énfasis.\n",
    "- Solo contabilizar repeticiones en SUSTANTIVOS, ADJETIVOS, VERBOS y ADVERBIOS.\n",
    "- No contar conjugaciones verbales ni perífrasis verbales (auxiliar + infinitivo/gerundio/participio).\n",
    "- Se analiza únicamente el párrafo entregado.\n",
    "\n",
    "Tu respuesta debe seguir esta estructura:\n",
    "\n",
    "{\n",
    "  \"errores_vocabulario_amplitud\": {\n",
    "        \"palabra1\": [\"n veces\"],\n",
    "        \"palabra2\": [\"n veces\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "INSTRUCCIONES PARA EL FORMATO:\n",
    "- Devuelve SOLO palabras repetidas con su número de apariciones.\n",
    "- NO incluyas texto corregido ni el párrafo original.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    parrafos = [p.strip() for p in texto.split(\"\\n\") if p.strip()]  \n",
    "\n",
    "    errores_por_texto = {\"id_texto\": i, \"errores_vocabulario_amplitud\": {}}\n",
    "\n",
    "    for j, parrafo in enumerate(parrafos, start=1):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt_amplitud},\n",
    "            {\"role\": \"user\", \"content\": parrafo}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=DEPLOYMENT_GPT,\n",
    "                messages=messages,\n",
    "                # temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "\n",
    "            respuesta_limpia = response.choices[0].message.content.strip()\n",
    "            resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "            errores_por_texto[\"errores_vocabulario_amplitud\"][f\"parrafo_{j}\"] = resultado_json.get(\"errores_vocabulario_amplitud\", {})\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error al parsear JSON en texto {i}, párrafo {j}: {e}\")\n",
    "            print(\"Respuesta cruda recibida:\")\n",
    "            print(respuesta_limpia)\n",
    "\n",
    "    resultados.append(errores_por_texto)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_amplitud.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163e45f",
   "metadata": {},
   "source": [
    "### Precisión léxica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd8d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\voc_precision.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_precision = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.\n",
    "\n",
    "Analiza EXCLUSIVAMENTE la dimensión de PRECISIÓN LÉXICA, según los siguientes criterios:\n",
    "\n",
    "A) USO INCORRECTO DE SIGNIFICADOS:\n",
    "- Detecta palabras usadas con un significado equivocado que cambien el sentido del texto.\n",
    "- Ejemplo: “absceso” por “acceso”, “actitud” por “aptitud”.\n",
    "\n",
    "B) EXTRANJERISMOS:\n",
    "- Señala extranjerismos que NO estén en comillas, cursiva o introducidos explícitamente por el autor.\n",
    "- Ejemplo incorrecto: usar \"online\" sin comillas ni contexto en vez de “en línea”.\n",
    "- No sanciones extranjerismos correctos o presentados como citas.\n",
    "\n",
    "C) REDUNDANCIAS:\n",
    "- Detecta repeticiones innecesarias de palabras o ideas.\n",
    "- Ejemplo: “salir para afuera”, “volar por los aires”, “hace un tiempo atrás”.\n",
    "\n",
    "Tu respuesta debe seguir esta estructura:\n",
    "\n",
    "{\n",
    "  \"errores_precision\": {\n",
    "        \"error_1\": [\"error → corrección\", CRITERIO],\n",
    "        \"error_2\": [\"error → corrección\", CRITERIO],\n",
    "        ...,\n",
    "        \"error_n\": [\"error → corrección\", CRITERIO]\n",
    "  }\n",
    "}\n",
    "\n",
    "REGLAS:\n",
    "- En CRITERIO indica \"USO INCORRECTO DE SIGNIFICADOS\", \"EXTRANJERISMO\" o \"REDUNDANCIA\".\n",
    "- Enumera todos los errores encontrados bajo la clave \"errores_vocabulario_precision\".\n",
    "- En cada caso, muestra el fragmento MÁS BREVE posible con el error.\n",
    "- Da una corrección propuesta o explica por qué es impreciso.\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_precision},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_precision.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e747ad",
   "metadata": {},
   "source": [
    "### Registro formal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a89a72a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\voc_formal.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_formal = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.\n",
    "\n",
    "Analiza EXCLUSIVAMENTE la dimensión de VOCABULARIO DE ADECUACIÓN AL REGISTRO DE HABLA FORMAL, según los siguientes criterios:\n",
    "\n",
    "1) SEGUNDA PERSONA SINGULAR:\n",
    "- Detecta uso del pronombre “tú” o verbos conjugados en segunda persona singular.\n",
    "- Ejemplo: \"Cuando postulas a un trabajo, tú tienes que pasar una entrevista\".\n",
    "\n",
    "2) ABREVIACIONES:\n",
    "- Señala formas abreviadas propias de la oralidad.\n",
    "- Ejemplo: “profe” por “profesor/a”, “finde” por “fin de semana”.\n",
    "\n",
    "3) COLOQUIALISMOS: uso de expresiones coloquiales (expresiones propias de la conversación informal); por ejemplo: “socio” por “amigo”, “cachar” por “comprender” o “darse cuenta”, “pega” por “trabajo”; el uso de calificativos más expresivos: “mina” por “guapa”, “bacán” por “excelente”, “pichiruche” por “insignificante”; el uso de diminutivos y el prefijo “super” para amplificar valor.\n",
    "\n",
    "4) ESCRITURA DE PALABRAS CON SÍMBOLOS O CARACTERES NO GRAFEMATICOS: sustitución de letras por símbolos para representar palabras (ejemplo: \"q’\" por \"que\", \"total%\" por \"totalmente\", \"publicaØ\" por \"publicación\").\n",
    "\n",
    "Tu respuesta debe seguir esta estructura:\n",
    "\n",
    "{\n",
    "  \"errores_vocabulario_formal\": {\n",
    "        \"error_1\": [\"error → corrección sugerida\", CRITERIO],\n",
    "        \"error_2\": [\"error → corrección sugerida\"], CRITERIO],\n",
    "        ...,\n",
    "        \"error_n\": [\"error → corrección sugerida\", CRITERIO]\n",
    "  }\n",
    "}\n",
    "\n",
    "REGLAS:\n",
    "- En \"CRITERIO\", indica si el criterio es \"SEGUNDA PERSONA SINGULAR\", \"ABREVIACIONES\", \"COLOQUIALISMOS\" o \"CÓDIGO ESCRITO NO FORMAL\".\n",
    "- Enumera todos los errores encontrados bajo la clave \"errores_vocabulario_formal\".\n",
    "- En cada caso, muestra el fragmento MÁS BREVE posible con el error.\n",
    "- Ofrece una corrección sugerida acorde al registro formal.\n",
    "- NO incluyas el texto completo corregido.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- NO INCLUYAS ERRORES DE ORTOGRFÍA ACENTUAL LITERAL NI PUNTUAL.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_formal},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_formal.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")\n",
    "\n",
    "# 4) CÓDIGO ESCRITO NO FORMAL:\n",
    "# - Detecta usos innecesarios de caracteres o símbolos en el español, sin incluiir til\n",
    "# que alteren la escritura formal con símbolos o caracteres que no son letras ni tildes.\n",
    "# - Ejemplos: \"q’\" por \"que\", \"total%\" por \"totalmente\", \"publicaØ\" por \"publicación\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a14b0",
   "metadata": {},
   "source": [
    "## 3. Cohesión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e02a6",
   "metadata": {},
   "source": [
    "### Concordancia gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9be19cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\coh_concordancia.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_concordancia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.  \n",
    "\n",
    "Analiza EXCLUSIVAMENTE la dimensión de **COHESIÓN TEXTUAL: CONCORDANCIA GRAMATICAL**, según estas reglas:  \n",
    "\n",
    "Se consideran errores de concordancia:\n",
    "- Falta de concordancia entre **sustantivo y adjetivo**.  \n",
    "- Falta de concordancia entre **sujeto y predicado**.  \n",
    "- Falta de concordancia entre **pronombres relativos y sus antecedentes**.  \n",
    "- Falta de consistencia en el uso de **tiempos verbales**, SOLO en los siguientes casos:  \n",
    "  A) Cambio de tiempo verbal en una enumeración de acciones.  \n",
    "  B) Uso de tiempos no adecuados en cláusulas condicionales y concesivas.  \n",
    "\n",
    "Tu respuesta debe seguir esta estructura:  \n",
    "\n",
    "{\n",
    "  \"errores_cohesion_concordancia\": {\n",
    "    \"error_1\": [\"error → corrección\", \"tipo: sustantivo-adjetivo\"],\n",
    "    \"error_2\": [\"error → corrección\", \"tipo: sujeto-predicado\"],\n",
    "    \"error_3\": [\"error → corrección\", \"tipo: pronombre-relativo\"],\n",
    "    \"error_4\": [\"error → corrección\", \"tipo: A\"],\n",
    "    \"error_5\": [\"error → corrección\", \"tipo: B\"],\n",
    "    ...\n",
    "    \"error_n\": [\"error → corrección\", \"tipo: ...\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "REGLAS:  \n",
    "- En \"errores_cohesion_concordancia\" lista todos los errores detectados.  \n",
    "- Cada error debe mostrarse con el fragmento MÁS BREVE posible (no frases completas).  \n",
    "- Especifica en cada caso el tipo de error:  \n",
    "  - \"sustantivo-adjetivo\"  \n",
    "  - \"sujeto-predicado\"  \n",
    "  - \"pronombre-relativo\"  \n",
    "  - \"A\" (enumeración de acciones)  \n",
    "  - \"B\" (cláusulas condicionales o concesivas)  \n",
    "- NO incluyas el texto completo corregido.  \n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.  \n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_concordancia},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_concordancia.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671de2a2",
   "metadata": {},
   "source": [
    "### Conexión textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b437ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\coh_conexion.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_conexion = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.  \n",
    "\n",
    "Analiza EXCLUSIVAMENTE la dimensión de **COHESIÓN TEXTUAL: CONEXIÓN TEXTUAL**, según estas reglas:  \n",
    "\n",
    "Se consideran errores de conexión textual:  \n",
    "1. Uso inadecuado de preposiciones o rección: falta la preposición o se usa una preposición incorrecta.  \n",
    "   - Incluye queísmo (uso de \"que\" sin \"de\" cuando corresponde) y dequeísmo (uso de \"de que\" cuando solo corresponde \"que\").  \n",
    "2. Uso inadecuado de locuciones preposicionales u otras construcciones lexicales de carácter conectivo (ej.: \"sobre la base de\", \"a razón de\", \"en relación con\") **cuando afecten la lógica de conexión oracional y/o textual**.  \n",
    "3. Ausencia de conectores o uso de conectores inadecuados para expresar la idea que se busca; mal uso de organizadores textuales (ej.: \"en primer lugar\", \"por un lado\", etc.).  \n",
    "\n",
    "Tu respuesta debe seguir esta estructura:  \n",
    "\n",
    "{\n",
    "  \"errores_cohesion_conexion\": {\n",
    "    \"error_1\": [\"error → corrección\", \"tipo: preposición/rección\"],\n",
    "    \"error_2\": [\"error → corrección\", \"tipo: queísmo\"],\n",
    "    \"error_3\": [\"error → corrección\", \"tipo: dequeísmo\"],\n",
    "    \"error_4\": [\"error → corrección\", \"tipo: locución-preposicional\"],\n",
    "    \"error_5\": [\"error → corrección\", \"tipo: conector-ausente\"],\n",
    "    \"error_6\": [\"error → corrección\", \"tipo: conector-inadecuado\"],\n",
    "    ...\n",
    "    \"error_n\": [\"error → corrección\", \"tipo: ...\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "REGLAS:  \n",
    "- En \"errores_cohesion_conexion\" lista todos los errores detectados.  \n",
    "- Cada error debe mostrarse con el fragmento MÁS BREVE posible (no frases completas).  \n",
    "- Especifica siempre el tipo de error con una de estas categorías:  \n",
    "  - \"preposición/rección\"  \n",
    "  - \"queísmo\"  \n",
    "  - \"dequeísmo\"  \n",
    "  - \"locución-preposicional\"  \n",
    "  - \"conector-ausente\"  \n",
    "  - \"conector-inadecuado\"  \n",
    "- NO incluyas el texto completo corregido.  \n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.  \n",
    "- NO INCLUYAS ERRORES DE ORTOGRFÍA ACENTUAL LITERAL NI PUNTUAL.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_conexion},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_conexion.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed729a1d",
   "metadata": {},
   "source": [
    "### Referencias y correferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2a29d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\coh_referencias.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_referencias = \"\"\"\n",
    "Eres un asistente experto en corrección de textos.  \n",
    "\n",
    "Analiza EXCLUSIVAMENTE la dimensión de **COHESIÓN TEXTUAL: REFERENCIAS Y CORREFERENCIAS**, según estas reglas:  \n",
    "\n",
    "Se consideran errores de referencia y correferencia:  \n",
    "- Pronombres o mecanismos de correferencia que no tengan un referente claro en el texto (ej.: \"esto\", \"lo anterior\", \"esa situación\").  \n",
    "\n",
    "Tu respuesta debe seguir esta estructura:  \n",
    "\n",
    "{\n",
    "  \"errores_cohesion_referencia\": {\n",
    "    \"error_1\": [\"error → corrección\", \"tipo: pronombre-sin-referencia\"],\n",
    "    \"error_2\": [\"error → corrección\", \"tipo: pronombre-sin-referencia\"],\n",
    "    ...\n",
    "    \"error_n\": [\"error → corrección\", \"tipo: pronombre-sin-referencia\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "REGLAS:  \n",
    "- En \"errores_cohesion_referencia\" lista todos los errores detectados.  \n",
    "- Cada error debe mostrarse con el fragmento MÁS BREVE posible que contenga el error (no frases completas).  \n",
    "- Todos los errores se clasifican como \"tipo: pronombre-sin-referencia\".  \n",
    "- NO incluyas el texto completo corregido.  \n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON. \n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_referencias},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_referencias.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
