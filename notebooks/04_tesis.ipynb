{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ceac44e",
   "metadata": {},
   "source": [
    "# Ámbito 2: Calidad de la Argumentación\n",
    "## Dimensión: Tesis\n",
    "\n",
    "En este notebook se probarán Prompts de GPT para la corrección de la dimensión Tesis correspondiendiente al Ámbito 2 de la Rúbrica del Proyecto de Escritura. También se agregarán las demás dimensiones del Ámbito 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\tesis.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "textos = textos  # Para pruebas, limitar a 2 textos\n",
    "\n",
    "prompt_tesis_template = prompt_tesis_template = \"\"\"Analiza el texto argumentativo que te entregaré y determina EXCLUSIVAMENTE los elementos necesarios para evaluar según los siguientes criterios y definiciones:\n",
    "\n",
    "### Definiciones:\n",
    "- **Tesis:** Afirmación central y explícita que el autor defiende sobre el tema. Es un enunciado completo, subrayable, con verbo principal conjugado y que expresa una posición defendible (puede incluir explícita o implícitamente un juicio de valor, pero NO es obligatorio que lo haga mediante un adjetivo). Representa la idea central que guía la argumentación.\n",
    "- **Postura explícita:** Implica una declaración de acuerdo o desacuerdo personal EXPRESA. Ejemplos: “Yo no estoy de acuerdo con…”, “A mí no me parece…”, “Yo no creo…”. En este caso la postura es aislable y subrayable en el texto.\n",
    "- **Postura implícita:** Implica una declaración de acuerdo o desacuerdo personal IMPLÍCITA, la cual solo puede deducirse a partir de la lectura global del escrito. Una postura implícita no es aislable ni subrayable de forma directa y no deben poder detectarse dos posturas contrarias igualmente desarrolladas dentro de la lectura global.\n",
    "- **Postura:** Término general que incluye tanto postura explícita como implícita. Se trata de una declaración inicial o básica de posición frente al tema, sin argumentación desarrollada; es como una “tesis embrionaria”: muestra hacia dónde va el autor pero sin formularse como proposición argumentativa completa.\n",
    "\n",
    "### Criterios de evaluación TESIS:\n",
    "- **3 puntos (Tesis explícita):** Se presenta una tesis EXPLÍCITA, clara, con verbo principal conjugado y posible de subrayar.\n",
    "- **2 puntos (Postura explícita):** Se presenta una postura EXPLÍCITA, aislable/subrayable.\n",
    "- **1 punto (Postura implícita):** Se presenta una postura IMPLÍCITA, deducible de la lectura global.\n",
    "- **0 puntos (Sin tesis ni postura):** Ninguno de los casos anteriores. No es posible identificar una tesis ni una postura en el texto.\n",
    "\n",
    "### Tu respuesta debe ser un JSON válido con la siguiente estructura EXACTA:\n",
    "{{\n",
    "  \"tesis_o_postura\": \"Texto de la tesis o postura identificada (o 'No identificada' si no hay)\",\n",
    "  \"clasificación\": \"tesis explícita / postura explícita / postura implícita / sin tesis\",\n",
    "  \"nivel_logro\": 3 | 2 | 1 | 0,\n",
    "  \"justificación\": \"Explica brevemente por qué asignaste esta clasificación y nivel\"\n",
    "}}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Identifica la tesis o postura en la forma más breve y precisa posible.\n",
    "- Si no hay tesis ni postura, indica claramente \"No identificada\".\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_tesis = prompt_tesis_template.format(essay=texto)\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_tesis}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"tesis.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd30103",
   "metadata": {},
   "source": [
    "## Dimensión: Calidad de la argumentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "055a8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio del proyecto (un nivel arriba de notebooks)\n",
    "proyecto_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Ruta absoluta al archivo JSON\n",
    "ruta_json = os.path.join(proyecto_dir, \"resultados\", \"02\", \"tesis.json\")\n",
    "\n",
    "with open(ruta_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    tesis_json = json.load(f)\n",
    "\n",
    "# 2️⃣ Crear la lista de tesis detectadas\n",
    "tesis_list = [item[\"resultado\"][\"tesis_o_postura\"] for item in tesis_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c1893a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\argumentacion.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_argumentos_template = \"\"\"Analiza el texto argumentativo que te entregaré y determina EXCLUSIVAMENTE los elementos necesarios según los siguientes criterios y definiciones. Te entregaré la tesis detectada previamente, para que relaciones los elementos con ella:\n",
    "\n",
    "### Definiciones de ARGUMENTOS:\n",
    "- **Argumentos sólidos:** Datos, hechos, cifras, argumentos causales, deductivos, inductivos y opiniones fundadas que se relacionan lógicamente con la tesis.\n",
    "- **Argumentos débiles:** Generalizaciones, argumentos de autoridad, falacias y otros recursos poco fundamentados.\n",
    "- **Argumentos afectivo-persuasivos:** Sentimientos, sensaciones, opiniones infundadas, apelación a la emotividad del lector (temores, deseos inconscientes, supersticiones, falsas creencias, etc.).\n",
    "\n",
    "### Niveles de logro por ARGUMENTOS:\n",
    "- **3 puntos:** Se presentan al menos tres argumentos sólidos relacionados con la tesis planteada, sin incluir argumentos afectivo-persuasivos.\n",
    "- **2 puntos:** Se presentan dos argumentos sólidos y al menos un argumento débil que se relacionan con la tesis planteada, sin incluir argumentos afectivo-persuasivos.\n",
    "- **1 punto:** \n",
    "  - Se presentan solo dos argumentos sólidos relacionados con la tesis planteada, sin incluir argumentos débiles ni afectivo-persuasivos,  \n",
    "  O  \n",
    "  - Se presenta un argumento sólido y al menos dos argumentos débiles relacionados con la tesis, sin incluir afectivo-persuasivos,  \n",
    "  O  \n",
    "  - Se presentan al menos tres argumentos débiles relacionados con la tesis, sin incluir afectivo-persuasivos.\n",
    "- **0 puntos:** Se presenta al menos un argumento afectivo-persuasivo que se relaciona con la tesis,  \n",
    "O  \n",
    "No se presentan argumentos (el texto es expositivo, un punteo de oraciones, formulación de preguntas, etc.).\n",
    "\n",
    "### Tu respuesta debe ser un JSON válido con la siguiente estructura EXACTA:\n",
    "{{\n",
    "  \"argumentos_solidos\": [\"Argumento sólido 1\", \"Argumento sólido 2\", ...],\n",
    "  \"argumentos_debiles\": [\"Argumento débil 1\", \"Argumento débil 2\", ...],\n",
    "  \"argumentos_afectivo_persuasivos\": [\"Argumento afectivo 1\", \"Argumento afectivo 2\", ...],\n",
    "  \"nivel_logro_argumentacion\": 3 | 2 | 1 | 0,\n",
    "  \"justificación\": \"Explica brevemente por qué asignaste este nivel\"\n",
    "}}\n",
    "\n",
    "### Tesis detectada previamente:\n",
    "{detected_thesis}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Si no hay argumentos de algún tipo, devuelve un array vacío [] en ese campo.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_argumentos = prompt_argumentos_template.format(essay=texto, detected_thesis=tesis_list[i-1])\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_argumentos}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"argumentacion.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a55104",
   "metadata": {},
   "source": [
    "## Dimensión: Contraargumentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\02\\contraargumentos.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_contraargumentos_template = \"\"\"Analiza el texto argumentativo que te entregaré y determina EXCLUSIVAMENTE los elementos necesarios según los siguientes criterios y definiciones. Te entregaré la tesis detectada previamente, para que relaciones los elementos con ella:\n",
    "\n",
    "### Definiciones de CONTRAARGUMENTACIÓN:\n",
    "- **Contraargumentación:** Se presenta al menos un contrargumento que contiene una objeción a la tesis planteada, se analiza detalladamente (se presenta el contrargumento y se explica su sentido) y luego se refuta.\n",
    "- **Mencionar un contrargumento:** Hacer referencia a algún argumento de la postura opuesta.\n",
    "- **Desarrollar un contrargumento:** Explicarlo o fundamentarlo desde la postura opuesta.\n",
    "- **Rebatir o refutar:** Plantear argumentos para oponerse al contrargumento planteado.\n",
    "\n",
    "### Niveles de logro por CONTRAARGUMENTACIÓN:\n",
    "- **3 puntos:** Se menciona, desarrolla y rebate al menos un contrargumento.\n",
    "- **2 puntos:** Se menciona y rebate al menos un contrargumento.\n",
    "- **1 punto:** Se desarrolla o menciona al menos un contrargumento, pero no se rebate.\n",
    "- **0 puntos:** NO se mencionan contrargumentos.\n",
    "\n",
    "### Tu respuesta debe ser un JSON válido con la siguiente estructura EXACTA:\n",
    "{{\n",
    "  \"contrargumentos\": [\n",
    "    {{\n",
    "      \"texto\": \"Texto completo del contrargumento\",\n",
    "      \"mencionado\": True | False,\n",
    "      \"desarrollado\": True | False,\n",
    "      \"rebatido\": True | False\n",
    "    }},\n",
    "    ...\n",
    "  ],\n",
    "  \"nivel_logro_contraargumentacion\": 3 | 2 | 1 | 0,\n",
    "  \"justificación\": \"Explica brevemente por qué asignaste este nivel\"\n",
    "}}\n",
    "\n",
    "### Tesis detectada previamente:\n",
    "{detected_thesis}\n",
    "\n",
    "### Texto a evaluar:\n",
    "{essay}\n",
    "\n",
    "### INSTRUCCIONES CRÍTICAS:\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Cada contrargumento debe aparecer **solo una vez** en la lista, con sus campos booleanos correspondientes.\n",
    "- Si no hay contrargumentos, devuelve un array vacío [] en \"contrargumentos\".\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    prompt_contraargumentos = prompt_contraargumentos_template.format(essay=texto, detected_thesis=tesis_list[i-1])\n",
    "\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'Realiza las tareas de corrección que te solicite para un texto entregado'},\n",
    "        {\"role\": \"user\", \"content\": prompt_contraargumentos}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"02\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"contraargumentos.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
