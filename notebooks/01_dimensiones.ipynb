{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1178efee",
   "metadata": {},
   "source": [
    "# Enfoque del Análisis por Dimensión - Ámbito 1: Aspectos de Estructura Textual\n",
    "\n",
    "En este documento se sigue el enfoque de **probar la modalidad de los prompts por dimensión** en el ámbito 1 de **Aspectos de estructura textual**, considerando específicamente las dimensiones de:\n",
    "\n",
    "- Ortografía  \n",
    "- Vocabulario  \n",
    "- Cohesión  \n",
    "\n",
    "Para hacer los resultados más **entendibles y analizables**, se evalúan los 20 textos enviados por Nicolás y por mi para tener un marco de comparación para los resultados que entreguen las consultas a la API de Azure OpenIA.  \n",
    "\n",
    "Se ha decidido **descartar el uso de `LangChain`**, debido a que no se ajusta a los objetivos de este análisis y podría introducir complejidades innecesarias en la evaluación de las dimensiones textuales.  \n",
    "\n",
    "A continuación, se muestra cómo **el prompt es enviado al texto**, así como el **prompt completo**, que abarca de manera ambiciosa **todas las dimensiones del Ámbito 1**, según el detalle que se puede observar en el contenido del prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae085762",
   "metadata": {},
   "source": [
    "### Ortografía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccea08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\01\\ort_macro.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_ortografia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. Aplica estas reglas al texto:\n",
    "\n",
    "ORTOGRAFÍA\n",
    "   - Ortografía acentual: errores en tildes según normas generales y especiales.\n",
    "       Ejemplos: esta/está, animos/ánimos\n",
    "   - Ortografía literal: errores en letras dentro de palabras.\n",
    "       Omisión: \"alchol\" → \"alcohol\"\n",
    "       Sustitución: \"fotocopeo\" → \"fotocopio\"\n",
    "       Adición: \"rrallado\" → \"rallado\"\n",
    "       Ejemplos adicionales: \"apartir\" → \"a partir\", \"através\" → \"a través\", \"porsiacaso\" → \"por si acaso\"\n",
    "   - Ortografía puntual: errores en signos de puntuación según normas RAE.\n",
    "       Incluye: coma, punto, punto y coma, signos de exclamación e interrogación\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{\n",
    "  \"texto_original_preview\": \"Primeros 100 caracteres del texto...\",\n",
    "  \"errores_detectados\": {\n",
    "        \"ortografia acentual\": [\"error → corrección\"],\n",
    "        \"ortografia literal\": [\"error → corrección\"],\n",
    "        \"ortografia puntual\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"texto_original_preview\" incluye SOLO los primeros 100 caracteres del texto original.\n",
    "- En \"errores_detectados\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de ORTOGRAFÍA, pero mira todo el contexto para detectar errores correctamente.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_ortografia},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI GPT5)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"01\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"ort_macro.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820ccd1",
   "metadata": {},
   "source": [
    "### Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bee6a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\01\\voc_macro.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_vocabulario = \"\"\"\n",
    "Analiza el siguiente texto en base a la dimensión de VOCABULARIO:\n",
    "\n",
    "VOCABULARIO\n",
    "   - Amplitud: evitar repetición innecesaria de sustantivos, adjetivos y adverbios.\n",
    "       Ejemplos: contaminación/ ecosistema / polución / ambiente\n",
    "   - Precisión léxica: uso incorrecto de palabras que confunden el sentido; incluye redundancias.\n",
    "       Ejemplos: “absceso” → “acceso”, “actitud” → “aptitud”; “salir para afuera”, “hace un tiempo atrás”\n",
    "   - Registro formal: evitar expresiones informales, abreviaciones o coloquialismos.\n",
    "       Ejemplos: “profe” → “profesor/a”, “finde” → “fin de semana”; “cachar” → “comprender”}\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{\n",
    "  \"texto_original_preview\": \"Primeros 100 caracteres del texto...\",\n",
    "  \"errores_detectados\": {\n",
    "        \"vocabulario amplitud\": [\"error → corrección\"],\n",
    "        \"vocabulario precision lexica\": [\"error → corrección\"],\n",
    "        \"vocabulario registro formal\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"texto_original_preview\" incluye SOLO los primeros 100 caracteres del texto original.\n",
    "- En \"errores_detectados\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de VOCABULARIO, pero mira todo el contexto para detectar errores correctamente.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_vocabulario},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI GPT5)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"01\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"voc_macro.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d4cc3",
   "metadata": {},
   "source": [
    "### Cohesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe03326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/20...\n",
      "Procesando texto 2/20...\n",
      "Procesando texto 3/20...\n",
      "Procesando texto 4/20...\n",
      "Procesando texto 5/20...\n",
      "Procesando texto 6/20...\n",
      "Procesando texto 7/20...\n",
      "Procesando texto 8/20...\n",
      "Procesando texto 9/20...\n",
      "Procesando texto 10/20...\n",
      "Procesando texto 11/20...\n",
      "Procesando texto 12/20...\n",
      "Procesando texto 13/20...\n",
      "Procesando texto 14/20...\n",
      "Procesando texto 15/20...\n",
      "Procesando texto 16/20...\n",
      "Procesando texto 17/20...\n",
      "Procesando texto 18/20...\n",
      "Procesando texto 19/20...\n",
      "Procesando texto 20/20...\n",
      "\n",
      "Todos los resultados guardados en ..\\resultados\\01\\coh_macro.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"escritos_seleccionados_a1.xlsx\")\n",
    "df = pd.read_excel(data_path)\n",
    "textos = df[\"escrito\"].dropna().tolist()\n",
    "\n",
    "prompt_cohesion = \"\"\"\n",
    "Analiza el siguiente texto en base a la dimensión de COHESIÓN TEXTUAL:\n",
    "\n",
    "COHESIÓN TEXTUAL\n",
    "   - Concordancia gramatical: errores de concordancia entre sustantivo/adjetivo, sujeto/predicado, pronombres y consistencia de tiempos verbales.\n",
    "   - Conexión textual: uso adecuado de preposiciones, locuciones y conectores; evitar queísmo/dequeísmo.\n",
    "   - Referencias y correferencias: pronombres u otros mecanismos sin referencia clara.\n",
    "       Ejemplos: “esto”, “lo anterior” sin antecedente claro\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{\n",
    "  \"texto_original_preview\": \"Primeros 100 caracteres del texto...\",\n",
    "  \"errores_cohesion_textual\": {\n",
    "        \"concordancia gramatical\": [\"error → corrección\"],\n",
    "        \"conexion textual\": [\"error → corrección\"],\n",
    "        \"referencias y correferencias\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"texto_original_preview\" incluye SOLO los primeros 100 caracteres del texto original.\n",
    "- En \"errores_cohesion_textual\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de COHESIÓN TEXTUAL, pero mira todo el contexto para detectar errores correctamente.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_cohesion},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            # temperature=0, (No es soportado en Azure OpenAI GPT5)\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"resultados\", \"01\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"coh_macro.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
