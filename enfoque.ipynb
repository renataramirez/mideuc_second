{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1178efee",
   "metadata": {},
   "source": [
    "# Enfoque del Análisis por Dimensión - Ámbito 1: Aspectos de Estructura Textual\n",
    "\n",
    "En este documento se sigue el enfoque de **probar la modalidad de los prompts por dimensión** en el ámbito 1 de **Aspectos de estructura textual**, considerando específicamente las dimensiones de:\n",
    "\n",
    "- Ortografía  \n",
    "- Vocabulario  \n",
    "- Cohesión  \n",
    "\n",
    "Para hacer los resultados más **entendibles y analizables**, se evalúa primero con un **solo texto**, tomando como referencia **el primer texto de la base de datos proporcionada**.  \n",
    "\n",
    "Se ha decidido **descartar el uso de `LangChain`**, debido a que no se ajusta a los objetivos de este análisis y podría introducir complejidades innecesarias en la evaluación de las dimensiones textuales.  \n",
    "\n",
    "A continuación, se muestra cómo **el prompt es enviado al texto**, así como el **prompt completo**, que abarca de manera ambiciosa **todas las dimensiones del Ámbito 1**, según el detalle que se puede observar en el contenido del prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14731c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado guardado en resultados\\correccion_ortografia_v1.json\n",
      "Preview del texto (20 chars): Los animos en nuestr\n",
      "Errores detectados: {\n",
      "  \"ortografia\": [\n",
      "    \"animos → ánimos\",\n",
      "    \"esta → está\",\n",
      "    \"conversacion → conversación\",\n",
      "    \"mas → más\",\n",
      "    \"claustrofobicas → claustrofóbicas\",\n",
      "    \"porque → por qué\",\n",
      "    \"quien → quién\",\n",
      "    \"velara → velará\",\n",
      "    \"deberia → debería\",\n",
      "    \"pretenciones → pretensiones\",\n",
      "    \"regulacion → regulación\",\n",
      "    \"limitarseles → limitarse les\",\n",
      "    \"vuestra → nuestra\",\n",
      "    \"asi → así\",\n",
      "    \"requieres en material → requieres el material\",\n",
      "    \"os → nos\",\n",
      "    \"vuestra → nuestra\",\n",
      "    \"ultimos → últimos\",\n",
      "    \"oportunides → oportunidades\",\n",
      "    \"acabara → acabará\",\n",
      "    \"pasaria → pasaría\",\n",
      "    \"pongamonos → pongámonos\",\n",
      "    \"habra → habrá\",\n",
      "    \"semanas → semana\",\n",
      "    \"Japon → Japón\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "df = pd.read_excel(\"df_ECE.xlsx\")\n",
    "texto_a_corregir = df.iloc[0][\"escrito\"]\n",
    "\n",
    "prompt_ortografia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. Aplica estas reglas al texto:\n",
    "\n",
    "1. ORTOGRAFÍA\n",
    "   1.1 Ortografía acentual: errores en tildes según normas generales y especiales.\n",
    "       Ejemplos: esta/está, animos/ánimos\n",
    "   1.2 Ortografía literal: errores en letras dentro de palabras.\n",
    "       Omisión: \"alchol\" → \"alcohol\"\n",
    "       Sustitución: \"fotocopeo\" → \"fotocopio\"\n",
    "       Adición: \"rrallado\" → \"rallado\"\n",
    "       Ejemplos adicionales: \"apartir\" → \"a partir\", \"através\" → \"a través\", \"porsiacaso\" → \"por si acaso\"\n",
    "   1.3 Ortografía puntual: errores en signos de puntuación según normas RAE.\n",
    "       Incluye: coma, punto, punto y coma, signos de exclamación e interrogación\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{\n",
    "  \"texto_original_preview\": \"Primeros 100 caracteres del texto...\",\n",
    "  \"errores_detectados\": {\n",
    "      \"ortografia\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"texto_original_preview\" incluye SOLO los primeros 100 caracteres del texto original.\n",
    "- En \"errores_detectados\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de ORTOGRAFÍA, pero mira todo el contexto para detectar errores correctamente.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_ortografia},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # Guardado \n",
    "    carpeta = \"resultados\"\n",
    "    archivo = \"correccion_ortografia_v1.json\"\n",
    "    output_path = os.path.join(carpeta, archivo)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultado guardado en {output_path}\")\n",
    "\n",
    "    # Imprimir preview de solo 20 caracteres\n",
    "    preview = resultado_json.get(\"texto_original_preview\", \"\")[:20]\n",
    "    print(\"Preview del texto (20 chars):\", preview)\n",
    "\n",
    "    # Imprimir errores detectados\n",
    "    errores = resultado_json.get(\"errores_detectados\", {})\n",
    "    print(\"Errores detectados:\", json.dumps(errores, ensure_ascii=False, indent=2))\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n",
    "\n",
    "    with open(\"respuesta_crudar.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(respuesta_limpia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ccea08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado guardado en resultados\\correccion_ortografia_v2.json\n",
      "Preview del texto (20 chars): Los animos en nuestr\n",
      "Errores detectados: {\n",
      "  \"ortografia acentual\": [\n",
      "    \"animos → ánimos\",\n",
      "    \"esta → está\",\n",
      "    \"porque → por qué\",\n",
      "    \"quien → quién\",\n",
      "    \"deberia → debería\",\n",
      "    \"pretenciones → pretensiones\",\n",
      "    \"regulacion → regulación\",\n",
      "    \"limitarseles → limitarse les\",\n",
      "    \"vuestra → su (contexto formal)\",\n",
      "    \"requieres → requiere (contexto formal)\",\n",
      "    \"mas → más\",\n",
      "    \"oportunides → oportunidades\",\n",
      "    \"acabara → acabará\",\n",
      "    \"habra → habrá\",\n",
      "    \"fines de semanas → fines de semana\"\n",
      "  ],\n",
      "  \"ortografia literal\": [\n",
      "    \"conversacion → conversación\",\n",
      "    \"claustrofobicas → claustrofóbicas\",\n",
      "    \"explicitara → explicará\",\n",
      "    \"velara → velará\",\n",
      "    \"victimas → víctimas\",\n",
      "    \"eficiencias → eficiencia\",\n",
      "    \"practica → práctica\",\n",
      "    \"negligente → negligencia\",\n",
      "    \"psicologica → psicológica\",\n",
      "    \"globalizacion → globalización\",\n",
      "    \"oportunides → oportunidades\",\n",
      "    \"malversacion → malversación\",\n",
      "    \"malinterpretacion → malinterpretación\",\n",
      "    \"cybercafes → cibercafés\",\n",
      "    \"Japon → Japón\"\n",
      "  ],\n",
      "  \"ortografia puntual\": [\n",
      "    \"errados, la → errados; la\",\n",
      "    \"nuevo. Ya → nuevo. Ya,\",\n",
      "    \"denotar. Poco → denotar: poco\",\n",
      "    \"quien velara → quién velará\",\n",
      "    \"contrato, todo → contrato; todo\",\n",
      "    \"eficiencias y → eficiencias, y\",\n",
      "    \"ellos, sobre → ellos: sobre\",\n",
      "    \"intimidad, asi → intimidad, así\",\n",
      "    \"riqueza y pobreza. Pues → riqueza y pobreza, pues\",\n",
      "    \"conexiones. Es → conexiones, es\",\n",
      "    \"presion algo → presión, algo\",\n",
      "    \"realidad). ¿Pero → realidad). ¿Pero,\",\n",
      "    \"competencias al → competencias, al\",\n",
      "    \"corresponde. Negar → corresponde: negar\",\n",
      "    \"resultados (eficiente y vitalmente) → resultados (eficientes y vitales).\",\n",
      "    \"pensar, que → pensar que\",\n",
      "    \"imposicion, primero → imposición: primero\",\n",
      "    \"contrato. El → contrato. El\",\n",
      "    \"habra otro → habrá otro\",\n",
      "    \"Japón, es → Japón es\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "df = pd.read_excel(\"df_ECE.xlsx\")\n",
    "texto_a_corregir = df.iloc[0][\"escrito\"]\n",
    "\n",
    "prompt_ortografia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. Aplica estas reglas al texto:\n",
    "\n",
    "1. ORTOGRAFÍA\n",
    "   1.1 Ortografía acentual: errores en tildes según normas generales y especiales.\n",
    "       Ejemplos: esta/está, animos/ánimos\n",
    "   1.2 Ortografía literal: errores en letras dentro de palabras.\n",
    "       Omisión: \"alchol\" → \"alcohol\"\n",
    "       Sustitución: \"fotocopeo\" → \"fotocopio\"\n",
    "       Adición: \"rrallado\" → \"rallado\"\n",
    "       Ejemplos adicionales: \"apartir\" → \"a partir\", \"através\" → \"a través\", \"porsiacaso\" → \"por si acaso\"\n",
    "   1.3 Ortografía puntual: errores en signos de puntuación según normas RAE.\n",
    "       Incluye: coma, punto, punto y coma, signos de exclamación e interrogación\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{\n",
    "  \"texto_original_preview\": \"Primeros 100 caracteres del texto...\",\n",
    "  \"errores_detectados\": {\n",
    "        \"ortografia acentual\": [\"error → corrección\"],\n",
    "        \"ortografia literal\": [\"error → corrección\"],\n",
    "        \"ortografia puntual\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"texto_original_preview\" incluye SOLO los primeros 100 caracteres del texto original.\n",
    "- En \"errores_detectados\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de ORTOGRAFÍA, pero mira todo el contexto para detectar errores correctamente.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_ortografia},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # Guardado \n",
    "    carpeta = \"resultados\"\n",
    "    archivo = \"correccion_ortografia_v2.json\"\n",
    "    output_path = os.path.join(carpeta, archivo)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultado guardado en {output_path}\")\n",
    "\n",
    "    # Imprimir preview de solo 20 caracteres\n",
    "    preview = resultado_json.get(\"texto_original_preview\", \"\")[:20]\n",
    "    print(\"Preview del texto (20 chars):\", preview)\n",
    "\n",
    "    # Imprimir errores detectados\n",
    "    errores = resultado_json.get(\"errores_detectados\", {})\n",
    "    print(\"Errores detectados:\", json.dumps(errores, ensure_ascii=False, indent=2))\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n",
    "\n",
    "    with open(\"respuesta_crudar.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(respuesta_limpia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820ccd1",
   "metadata": {},
   "source": [
    "*Evaluación por Dimensión Vocabulario y Sub-Dimensión Acentual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edbdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado guardado en resultados\\correccion_ortografia_v3a.json\n",
      "Preview del texto (20 chars): Los animos en nuestr...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "df = pd.read_excel(\"df_ECE.xlsx\")\n",
    "texto_a_corregir = df.iloc[0][\"escrito\"]\n",
    "\n",
    "prompt_ortografia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. \n",
    "\n",
    "Corrige solo los errores de ORTOGRAFÍA ACENTUAL del texto entregado, teniendo en cuenta para este ámbito se evalúa \n",
    "el correcto empleo de normas generales (palabras agudas, graves, esdrújulas y sobreesdrújulas) y especiales\n",
    "(acento dierético y diacrítico) de las reglas ortográficas que rigen la acentuación de la lengua española.\n",
    "\n",
    "Tu respuesta debe seguir la siguiente estructura:\n",
    "\n",
    "{\n",
    "  \"texto_original_preview\": \"...\",\n",
    "  \"errores_ortografia_acentual\": {\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        \"error_3\": [\"error → corrección\"],\n",
    "        ...,\n",
    "        \"error_n\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"texto_original_preview\" incluye SOLO los primeros 100 caracteres del texto original.\n",
    "- En \"errores_ortografia_acentual\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de ORTOGRAFÍA ACENTUAL, pero mira todo el contexto para detectar errores correctamente.\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_ortografia},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # Guardado \n",
    "    carpeta = \"resultados\"\n",
    "    archivo = \"correccion_ortografia_v3a.json\"\n",
    "    output_path = os.path.join(carpeta, archivo)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultado guardado en {output_path}\")\n",
    "\n",
    "    # Texto\n",
    "    preview = resultado_json.get(\"texto_original_preview\", \"\")[:20]\n",
    "    print(\"Preview del texto (20 chars):\", preview + \"...\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n",
    "\n",
    "    with open(\"respuesta_crudar.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(respuesta_limpia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ceaf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando texto 1/10...\n",
      "Preview: ...\n",
      "Procesando texto 2/10...\n",
      "Preview: ...\n",
      "Procesando texto 3/10...\n",
      "Preview: ...\n",
      "Procesando texto 4/10...\n",
      "Preview: ...\n",
      "Procesando texto 5/10...\n",
      "Preview: ...\n",
      "Procesando texto 6/10...\n",
      "Preview: ...\n",
      "Procesando texto 7/10...\n",
      "Preview: ...\n",
      "Procesando texto 8/10...\n",
      "Preview: ...\n",
      "Procesando texto 9/10...\n",
      "Preview: ...\n",
      "Procesando texto 10/10...\n",
      "Preview: ...\n",
      "\n",
      "Todos los resultados guardados en correcciones_selectas\\ortografia_acentual.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "df = pd.read_excel(\"escritos_seleccionados_ort.xlsx\")\n",
    "textos = df[\"escrito\"].dropna().tolist() \n",
    "\n",
    "prompt_ortografia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. \n",
    "\n",
    "Corrige EXCLUSIVAMENTE los errores de ORTOGRAFÍA ACENTUAL del texto entregado.\n",
    "\n",
    "Se evalúa el correcto empleo de normas generales (palabras agudas, graves, esdrújulas y sobreesdrújulas) y especiales\n",
    "(acento dierético y diacrítico) de las reglas ortográficas que rigen la acentuación de la lengua española.\n",
    "\n",
    "Tu respuesta debe seguir la siguiente estructura:\n",
    "\n",
    "{\n",
    "  \"errores_ortografia_acentual\": {\n",
    "        \"error_1\": [\"error → corrección\"],\n",
    "        \"error_2\": [\"error → corrección\"],\n",
    "        \"error_3\": [\"error → corrección\"],\n",
    "        ...,\n",
    "        \"error_n\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "- En \"errores_ortografia_acentual\" lista todos los errores encontrados.\n",
    "- NO uses markdown, NO incluyas ```json, devuelve SOLO el JSON.\n",
    "- Solo analiza la categoría de ORTOGRAFÍA ACENTUAL, pero mira todo el contexto para detectar errores correctamente.\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\"\"\"\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i, texto in enumerate(textos, start=1):\n",
    "    print(f\"Procesando texto {i}/{len(textos)}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_ortografia},\n",
    "        {\"role\": \"user\", \"content\": texto}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=DEPLOYMENT_GPT,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        respuesta_limpia = response.choices[0].message.content.strip()\n",
    "        resultado_json = json.loads(respuesta_limpia)\n",
    "        resultados.append({\n",
    "            \"id_texto\": i,\n",
    "            \"resultado\": resultado_json\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al parsear JSON en texto {i}: {e}\")\n",
    "        print(\"Respuesta cruda recibida:\")\n",
    "        print(respuesta_limpia)\n",
    "\n",
    "output_path = os.path.join(\"correcciones_selectas\", \"ortografia_acentual.json\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\nTodos los resultados guardados en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a36f4e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado guardado en resultados\\correccion_ortografia_v3b.json\n",
      "Preview del texto (20 chars): ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "df = pd.read_excel(\"df_ECE.xlsx\")\n",
    "texto_a_corregir = df.iloc[0][\"escrito\"]\n",
    "\n",
    "prompt_ortografia = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. \n",
    "\n",
    "Corrige solo los errores de ORTOGRAFÍA LITERAL.\n",
    "\n",
    "dEVUELVE LA RESPUESTA EN formato JSON, dandome una por una las palabras malas y su corrección.\n",
    "\n",
    "###IMPORTATE\n",
    "RECUERDA NO INCLUIR ERRORES ORTÓGRAFICOS ACENTUALES, ES DECIR, FALTAS DE TILDES.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_ortografia},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # Guardado \n",
    "    carpeta = \"resultados\"\n",
    "    archivo = \"correccion_ortografia_v3b.json\"\n",
    "    output_path = os.path.join(carpeta, archivo)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultado guardado en {output_path}\")\n",
    "\n",
    "    # Texto\n",
    "    preview = resultado_json.get(\"texto_original_preview\", \"\")[:20]\n",
    "    print(\"Preview del texto (20 chars):\", preview + \"...\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n",
    "\n",
    "    with open(\"respuesta_crudar.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(respuesta_limpia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee6a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado guardado en resultados\\correccion_vocabulario_v1.json\n",
      "Preview texto original: \n",
      "Resultados análisis vocabulario: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_GPT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT\n",
    ")\n",
    "\n",
    "df = pd.read_excel(\"df_ECE.xlsx\")\n",
    "texto_a_corregir = df.iloc[0][\"escrito\"]\n",
    "\n",
    "prompt_vocabulario = \"\"\"\n",
    "Analiza el siguiente texto en base a la dimensión de VOCABULARIO:\n",
    "\n",
    "VOCABULARIO\n",
    "   - Amplitud: evitar repetición innecesaria de sustantivos, adjetivos y adverbios.\n",
    "   - Precisión léxica: uso incorrecto de palabras que confunden el sentido; incluye redundancias.\n",
    "   - Registro formal: evitar expresiones informales, abreviaciones o coloquialismos.\n",
    "\n",
    "Ejemplos:\n",
    "- Amplitud: contaminación/ ecosistema / polución / ambiente\n",
    "- Precisión léxica: “absceso” → “acceso”, “actitud” → “aptitud”; “salir para afuera”, “hace un tiempo atrás”\n",
    "- Registro formal: “profe” → “profesor/a”, “finde” → “fin de semana”; “cachar” → “comprender”\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Solo analiza la categoría de VOCABULARIO, pero mira todo el contexto para detectar errores correctamente.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con { y terminar con }.\n",
    "- No entregues una salida vacía; si no hay errores, indica \"No se encontraron errores\".\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{\n",
    "  \"texto_original_preview\": \"Primeros 20 caracteres del texto...\",\n",
    "  \"errores_detectados\": {\n",
    "      \"vocabulario\": [\"error → corrección\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_vocabulario},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # Guardado \n",
    "    carpeta = \"resultados\"\n",
    "    archivo = \"correccion_vocabulario_v1.json\"\n",
    "    output_path = os.path.join(carpeta, archivo)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultado guardado en {output_path}\")\n",
    "    print(\"Preview texto original:\", resultado_json.get(\"texto_original\", \"\")[:20])\n",
    "    print(\"Resultados análisis vocabulario:\", resultado_json.get(\"resultados\", \"\"))\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe03326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview texto original: \n",
      "Resultados análisis cohesión: \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"df_ECE.xlsx\")\n",
    "texto_a_corregir = df.iloc[0][\"escrito\"]\n",
    "\n",
    "prompt_cohesion = \"\"\"\n",
    "Analiza el siguiente texto en base a la dimensión de COHESIÓN TEXTUAL:\n",
    "\n",
    "3. COHESIÓN TEXTUAL\n",
    "   3.1 Concordancia gramatical: errores de concordancia entre sustantivo/adjetivo, sujeto/predicado, pronombres y consistencia de tiempos verbales.\n",
    "   3.2 Conexión textual: uso adecuado de preposiciones, locuciones y conectores; evitar queísmo/dequeísmo.\n",
    "   3.3 Referencias y correferencias: pronombres u otros mecanismos sin referencia clara.\n",
    "       Ejemplos: “esto”, “lo anterior” sin antecedente claro\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown (sin ```json o similares).\n",
    "- El JSON debe comenzar inmediatamente con { y terminar con }.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_cohesion},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # --- Guardar resultados en archivo JSON (opcional, descomentar si se quiere usar) ---\n",
    "    # output_path = \"resultado_cohesion.json\"\n",
    "    # with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "    # print(f\"Resultado guardado en {output_path}\")\n",
    "\n",
    "    print(\"Preview texto original:\", resultado_json.get(\"texto_original\", \"\")[:20])\n",
    "    print(\"Resultados análisis cohesión:\", resultado_json.get(\"resultados\", \"\"))\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b45f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado guardado en resultado_correccion.json\n",
      "Preview del texto: Los animos en nuestra actual pandemia no se hallan errados, la salud mental con respecto a lo que podemos denominar como la realidad del trabajo permanente no esta enfrentando nada nuevo...\n",
      "\n",
      "Estadísticas de errores:\n",
      "ORTOGRAFIA: 14 errores\n",
      "  - acentual: 9\n",
      "  - literal: 5\n",
      "VOCABULARIO: 6 errores\n",
      "  - precision_lexica: 3\n",
      "  - registro_formal: 3\n"
     ]
    }
   ],
   "source": [
    "prompt_completo = \"\"\"\n",
    "Eres un asistente experto en corrección de textos. Aplica estas reglas al texto:\n",
    "\n",
    "CATEGORÍAS Y SUBCATEGORÍAS DE ERRORES:\n",
    "\n",
    "1. ORTOGRAFÍA\n",
    "   1.1 Ortografía acentual: errores en tildes según normas generales y especiales.\n",
    "       Ejemplos: esta/está, animos/ánimos\n",
    "   1.2 Ortografía literal: errores en letras dentro de palabras.\n",
    "       Omisión: \"alchol\" → \"alcohol\"\n",
    "       Sustitución: \"fotocopeo\" → \"fotocopio\"\n",
    "       Adición: \"rrallado\" → \"rallado\"\n",
    "       Ejemplos adicionales: “apartir” → “a partir”, “através” → “a través”, “porsiacaso” → “por si acaso”\n",
    "   1.3 Ortografía puntual: errores en signos de puntuación según normas RAE.\n",
    "       Incluye: coma, punto, punto y coma, signos de exclamación e interrogación\n",
    "\n",
    "2. VOCABULARIO\n",
    "   2.1 Amplitud: evitar repetición innecesaria de sustantivos, adjetivos, verbos y adverbios.\n",
    "       Ejemplo: contaminación/ ecosistema / polución / ambiente\n",
    "   2.2 Precisión léxica: uso incorrecto de palabras que confunden el sentido; incluye redundancias.\n",
    "       Ejemplos: “absceso” → “acceso”, “actitud” → “aptitud”; “salir para afuera”, “hace un tiempo atrás”\n",
    "   2.3 Registro formal: evitar expresiones informales, abreviaciones o coloquialismos.\n",
    "       Ejemplos: “profe” → “profesor/a”, “finde” → “fin de semana”; “cachar” → “comprender”\n",
    "\n",
    "3. COHESIÓN TEXTUAL\n",
    "   3.1 Concordancia gramatical: errores de concordancia entre sustantivo/adjetivo, sujeto/predicado, pronombres y consistencia de tiempos verbales.\n",
    "   3.2 Conexión textual: uso adecuado de preposiciones, locuciones y conectores; evitar queísmo/dequeísmo.\n",
    "   3.3 Referencias y correferencias: pronombres u otros mecanismos sin referencia clara.\n",
    "       Ejemplos: “esto”, “lo anterior” sin antecedente claro\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "- Detecta errores según estas categorías y subcategorías.\n",
    "- Para CADA error, especifica la subcategoría exacta.\n",
    "- NO incluyas el texto corregido completo.\n",
    "- Devuelve SOLAMENTE JSON válido sin formato markdown.\n",
    "- El JSON debe comenzar inmediatamente con {{ y terminar con }}.\n",
    "\n",
    "ESTRUCTURA EXACTA REQUERIDA:\n",
    "{{\n",
    "  \"texto_original_preview\": \"Primeros 100 caracteres del texto...\",\n",
    "  \"errores_detectados\": {{\n",
    "      \"ortografia\": [\n",
    "        {{\"error\": \"error original\", \"correccion\": \"corrección propuesta\", \"subcategoria\": \"acentual/literal/puntual\"}}\n",
    "      ],\n",
    "      \"vocabulario\": [\n",
    "        {{\"error\": \"error original\", \"correccion\": \"corrección propuesta\", \"subcategoria\": \"amplitud/precision_lexica/registro_formal\"}}\n",
    "      ],\n",
    "      \"cohesion\": [\n",
    "        {{\"error\": \"error original\", \"correccion\": \"corrección propuesta\", \"subcategoria\": \"concordancia/conexion/referencias\"}}\n",
    "      ]\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Enviar la petición a Azure OpenAI\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt_completo},\n",
    "    {\"role\": \"user\", \"content\": texto_a_corregir}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_GPT,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    respuesta_limpia = response.choices[0].message.content.strip()\n",
    "    resultado_json = json.loads(respuesta_limpia)\n",
    "\n",
    "    # Filtrar solo subcategorías válidas\n",
    "    categorias_validas = {\n",
    "        \"ortografia\": {\"acentual\", \"literal\", \"puntual\"},\n",
    "        \"vocabulario\": {\"amplitud\", \"precision_lexica\", \"registro_formal\"},\n",
    "        \"cohesion\": {\"concordancia_gramatical\", \"conexion_textual\", \"referencias_y_correferencias\"}\n",
    "    }\n",
    "\n",
    "    for categoria, subcategorias in resultado_json[\"errores_detectados\"].items():\n",
    "        resultado_json[\"errores_detectados\"][categoria] = [\n",
    "            error for error in subcategorias if error[\"subcategoria\"] in categorias_validas[categoria]\n",
    "        ]\n",
    "\n",
    "    # --- Guardar en archivo JSON ---\n",
    "    output_path = \"resultado_correccion.json\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Resultado guardado en {output_path}\")\n",
    "    print(\"Preview del texto:\", resultado_json.get(\"texto_original_preview\", \"\"))\n",
    "    \n",
    "    # Estadísticas de errores\n",
    "    if \"errores_detectados\" in resultado_json:\n",
    "        errores = resultado_json[\"errores_detectados\"]\n",
    "        print(\"\\nEstadísticas de errores:\")\n",
    "        for categoria, lista_errores in errores.items():\n",
    "            if lista_errores:\n",
    "                subcategorias = {}\n",
    "                for error in lista_errores:\n",
    "                    subcat = error.get(\"subcategoria\", \"sin_subcategoria\")\n",
    "                    subcategorias[subcat] = subcategorias.get(subcat, 0) + 1\n",
    "                \n",
    "                print(f\"{categoria.upper()}: {len(lista_errores)} errores\")\n",
    "                for subcat, count in subcategorias.items():\n",
    "                    print(f\"  - {subcat}: {count}\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error al parsear JSON: {e}\")\n",
    "    print(\"Respuesta cruda recibida:\")\n",
    "    print(respuesta_limpia)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
